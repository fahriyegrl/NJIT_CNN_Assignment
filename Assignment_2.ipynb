{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahriyegrl/NJIT_CNN_Assignment/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tajfsk_7JY3E"
      },
      "source": [
        "**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be first graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). However, any given item may be worth 4 or 8 points; if an item is worth 8 points, you need to accordingly scale the 0-4 grade.\n",
        "\n",
        "\n",
        "The total score must be re-scaled to 100. That should apply to all future assignments so that Canvas assigns the same weight on all assignments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SArgW_Vq-uTh"
      },
      "source": [
        "# <font color = 'blue'>  **Assignment 2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation Steps\n"
      ],
      "metadata": {
        "id": "fKHAiVXNz-2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We will work with this [mystery dataset](https://drive.google.com/open?id=1WLnWBThCYZ25pReI5DCwk2bgDaCrJxI_&authuser=ikoutis%40njit.edu&usp=drive_fs) that you can download and place to your google drive. You can then put it somewhere on your google drive and bring it into your Colab by following the steps in the following cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "5xtT_YAhmmXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import scipy.io\n",
        "\n",
        "#mat = scipy.io.loadmat('/content/gdrive/Shareddrives/graph-modification/data/mysteryDataset.mat')\n",
        "\n",
        "#mat = scipy.io.loadmat('/mysteryDataset.mat')"
      ],
      "metadata": {
        "id": "5AMaVk7jmn_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b525ac7-024b-4a34-a951-0e8997632954"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file contains\n",
        "\n",
        "* Two matrices $X$ and $X_1$ of numerical features. These datasets have the same dimensions (169343x80) but they are different.\n",
        "* An array $y$ of labels, ranging from 0-39.\n",
        "* The indices $otrain$ of a training set. These indices tell you what rows of the arrays $X,X_1,y$ correspond to the training points. You can use these to make two different training sets $(X[train], y[train])$ and $(X_1[train], y[train])$\n",
        "* Similarly, it contains the indexes for a validation and a test set, $ovalid$ and $otest$ respectively.\n",
        "\n",
        "The following cell shows how to access these arrays and assign them to local numpy objects."
      ],
      "metadata": {
        "id": "AsLbaghZrO-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mat = scipy.io.loadmat('mysteryDataset.mat')\n",
        "\n",
        "file_path = \"/content/gdrive/My Drive/mysteryDataset .mat\"\n",
        "mat = scipy.io.loadmat(file_path)"
      ],
      "metadata": {
        "id": "HQ0Oyva2F3fF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFzCOuH97O0G",
        "outputId": "5a7cfe23-df0d-4bbc-85ec-f932c52663eb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'X', 'X1', 'otest', 'otrain', 'ovalid', 'y'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mat['X']\n",
        "print(type(data))\n",
        "print(data.shape)\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slka77ZW7MEV",
        "outputId": "1c61951e-8fd6-4209-bb24-06bc267b8f37"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(169343, 80)\n",
            "[[-1.17172086e-05 -7.25280867e-06  5.12661752e-06 ...  8.41897191e-05\n",
            "   1.42267498e-05 -1.79510200e-05]\n",
            " [-1.11324893e-05 -4.08813759e-06  2.02800221e-06 ... -8.28714325e-05\n",
            "  -1.61708374e-05  1.97942889e-05]\n",
            " [-1.15048231e-05 -5.82459697e-06  4.93125101e-06 ...  2.49504038e-05\n",
            "   4.74029309e-06 -8.01156192e-06]\n",
            " ...\n",
            " [-1.14174907e-05 -6.78472981e-06  5.12786880e-06 ...  8.45869596e-05\n",
            "   1.28441318e-05 -5.47867305e-06]\n",
            " [-1.17641029e-05 -7.40347110e-06  5.22326732e-06 ...  9.09224602e-05\n",
            "   1.51560773e-05 -1.93930956e-05]\n",
            " [-1.16459906e-05 -4.51781688e-06  4.84513313e-06 ... -6.45753345e-06\n",
            "  -3.49332467e-06 -1.98055043e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is an example\n",
        "#ft = mat.get('X')\n"
      ],
      "metadata": {
        "id": "d0jvswNpwsOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'blue'> Question 1. Import the dataset and conver to torch tensors </font>\n",
        "\n",
        "Your task for this question is to adapt the above preparation steps, import all mentioned variables into numpy arrays, and then transform them to PyTorch tensors.\n"
      ],
      "metadata": {
        "id": "ALSnNeSw0JoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your answer goes here\n",
        "\n",
        "## Getting the data\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "X = mat['X']\n",
        "X1 = mat['X1']\n",
        "y = mat['y']\n",
        "print(X.shape)\n",
        "print(X1.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "C20aEPMG0z2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e6024c-86e2-4c75-8ed8-9d576c96832b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(169343, 80)\n",
            "(169343, 80)\n",
            "(169343, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "otrain = mat['otrain'].flatten() # Getting training indices\n",
        "ovalid = mat['ovalid'].flatten() # Validation indices\n",
        "otest = mat['otest'].flatten()    # Test indices"
      ],
      "metadata": {
        "id": "bhkRQdaE8qpy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(otrain.shape)\n",
        "print(ovalid.shape)\n",
        "print(otest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FECrBxn481z5",
        "outputId": "90bad60e-1985-4fef-9827-79d5964a0176"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90941,)\n",
            "(29799,)\n",
            "(48603,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Converting to PyTorch tensors\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "X1_tensor = torch.tensor(X1, dtype=torch.float32)\n",
        "\n",
        "\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "otrain_tensor = torch.tensor(otrain, dtype=torch.long)\n",
        "ovalid_tensor = torch.tensor(ovalid, dtype=torch.long)\n",
        "otest_tensor = torch.tensor(otest, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "IZjEA-FX8_0z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Getting the train, validation, test datasets\n",
        "\n",
        "# Create training sets\n",
        "X_train = X_tensor[otrain_tensor]\n",
        "X1_train = X1_tensor[otrain_tensor]\n",
        "y_train = y_tensor[otrain_tensor]\n",
        "\n",
        "# Create validation sets\n",
        "X_valid = X_tensor[ovalid_tensor]\n",
        "X1_valid = X1_tensor[ovalid_tensor]\n",
        "y_valid = y_tensor[ovalid_tensor]\n",
        "\n",
        "# Create test sets\n",
        "X_test = X_tensor[otest_tensor]\n",
        "X1_test = X1_tensor[otest_tensor]\n",
        "y_test = y_tensor[otest_tensor]\n"
      ],
      "metadata": {
        "id": "mxhz34869FFJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X1_train shape:\", X1_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"X1_valid shape:\", X1_valid.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"X1_test shape:\", X1_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFvreG3Y9r8S",
        "outputId": "bcc81787-2464-4d06-c423-dfdf2242a12b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([90941, 80])\n",
            "X1_train shape: torch.Size([90941, 80])\n",
            "y_train shape: torch.Size([90941, 1])\n",
            "X_valid shape: torch.Size([29799, 80])\n",
            "X1_valid shape: torch.Size([29799, 80])\n",
            "y_valid shape: torch.Size([29799, 1])\n",
            "X_test shape: torch.Size([48603, 80])\n",
            "X1_test shape: torch.Size([48603, 80])\n",
            "y_test shape: torch.Size([48603, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBjMZF1wGaUp"
      },
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 4)\n",
        "\n",
        "# G[1] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'blue'> Question 2. Write a functioning classifier in PyTorch </font>\n",
        "\n",
        "Write code that defines a classification model for the above dataset, and all other functions that are needed for its training. Apply your model on the two datsets $X,X_1$ and report the accuracy. The classifier should operate on the GPU.\n",
        "\n",
        "**Hint:** Re-use code we discussed for the Softmax Regression module."
      ],
      "metadata": {
        "id": "s7I1lmGM0skC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your answer goes here\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define MLP model\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size=80, hidden_size=256, num_classes=40):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_classes)  # No activation (CrossEntropyLoss handles Softmax)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "na0el-GE1qtY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlICv7kW1qte"
      },
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 8)\n",
        "\n",
        "# G[2] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'blue'> Question 3. Maximize the accuracy on the two datasets </font>\n",
        "\n",
        "Augment your classifier from Question-2 with any number and type of layers you want, with the goal to maximize the **validation** accuracy you achieve on the two datasets. Feel free to use any stopping criterion you want for the training process. The networks for $X$ and $X_1$ do not have be of the same architecture.\n",
        "\n",
        "Show your code, and add a text cell summarizing your idea and findings. Finally apply your models to the **test** set, and report the accuracy. Feel free to discuss your validation accuracy on Canvas. Also please avoid looking at the test set, until the very end.\n",
        "\n",
        "**Rubric**: All complete answers get 8 points, and the **top** test accuracy reported gets an extra 10\\% in the final quiz."
      ],
      "metadata": {
        "id": "gDmA1ZZL152G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your answer goes here"
      ],
      "metadata": {
        "id": "ySrVeueW31b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcYS1afK31cS"
      },
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 8)\n",
        "\n",
        "# G[3] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total score\n",
        "max_score = 20\n",
        "$inal_score = sum(G)*(100/max_score)"
      ],
      "metadata": {
        "id": "EZHVWBIjIuoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}